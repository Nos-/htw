%\subsection*{Speicherverwaltung: Einführung}
\slides{03}{2}
\section{Speicherhierarchie}
\slides{03}{3}

\subsection{Ebenen}
\slides{03}{4}
\slides{03}{5}

\section{Cache}
\subsection{Einführung}
\subsubsection{Motivation und Grundidee}
\slides{03}{6}

\subsubsection{Umsetzung der Idee}
\slides{03}{7}
\slides{03}{8}

\subsubsection{Hierarchie, Übertragungsmodi}
\slides{03}{9}

\subsection{Lokalität}
\subsubsection{Prinzip}
\slides{03}{10}
Beispiel Lokalität: Wenn man bei C Arrays multipliziert, kann je nach Schachtelung der Schleifen die Laufzeit leiden. In C werden Arrays zeilenweise gespeichert, multipliziert man die Arrays allerdings spaltenweise, so muss viel gesprungen werden, da die Speicherblöcke weiter auseinander liegen.

\subsubsection{Zeitliche Lokalität}
(Temporal Locality)
\slides{03}{11}

\subsubsection{Räumliche Lokalität}
(Spatial Locality)
\slides{03}{12}

\subsubsection{Bedeutung der Lokalität}
\slides{03}{13}

\subsubsection{Umsetzung des Lokalitätsprinzips}
\slides{03}{14}

\subsection{Zugriff}
\subsubsection{Anordnung bezüglich CPU und Hauptspeicher}
\slides{03}{15}
\subsubsection{Fehlzugriffe}
\slides{03}{16}
weiterhin:
\slides{03}{17}
\subsubsection*{Compulsory-Miss}
\slides{03}{18}

\subsubsection{Lesezugriffe}
\slides{03}{19}

\subsubsection{Schreibzugriffe}
\subsubsection*{Rückschreibestrategien}
\slides{03}{20}
\subsubsection*{Durchschreibverfahren}
\slides{03}{21}
\subsubsection*{Rückschreibeverfahren}
\slides{03}{22}
\subsubsection*{Write Hit und Write Miss}
\slides{03}{23}

\subsection{Kohärenz und Konsistenz}
\subsubsection{Kohärenz}
„Alle Speicherzugreifenden bekommen den richtigen Wert, wenn sie auf den Speicher zugreifen“
\unimptnt{
\subsubsection*{Kohärenz Beispiel mit Write-Through-Caches}
\slides{03}{24}
\subsubsection*{Kohärenz Beispiel mit Write-Back-Caches}
\slides{03}{25}
}

\subsubsection*{Speicherkohärenz}
\slides{03}{26}

\subsubsection*{Definition Kohärenz}
\slides{03}{27}
\slides{03}{28}

\subsubsection{Konsistenz}
\slides{03}{29}

\unimptnt{
\subsubsection*{Speicher-Konsistenz}
\slides{03}{30}
}

\subsubsection{Kohärenz-Protokolle}
\slides{03}{31}
\unimptnt{
\subsubsection*{Vereichnisbasiert}
\slides{03}{32}

\subsubsection*{Bus-Snooping}
\slides{03}{33}

Möglichkeiten:
\slides{03}{34}

\subsubsection*{MESI-Kohärenzprotokoll}
\slides{03}{35}
Verbesserungen:
\slides{03}{36}

\subsubsection*{Update-basierte Protokolle}
\slides{03}{37}
}

\section{Cacheorganisation}

\subsection{Realisierung}
\slides{03}{38}

\subsection{Aufbau eines Cache-Speichers}
\slides{03}{39}

\subsection{Begriffe}
\slides{03}{40}

\subsection{Direktabbildender Cache}
(Direct Mapped Cache)
\slides{03}{41}
Beispiel: Direkt abgebildeter Cache mit 8 Einträgen, Speicher mit $2^5$ Adressen: Die letzten Bits der Speicheradressen bestimmen die Position im Cache: $00001$, $01001$, $10001$ und $11001$ landen im Cache-Block $001$.
\unimptnt{
\slides{03}{42}
}

\subsection{vollassoziativer Cache}
(Fully Associative Cache)
\slides{03}{43}

\subsection{p-fach satzassoziativer Cache}
\slides{03}{44}
\unimptnt{
\slides{03}{45}

\subsection{Cache-Mapping: zusammenfassendes Beispiel}
\slides{03}{46}
Die 2. und 3. Caches geben dem Cache also eine Struktur vor, die die Nachteile des voll-assoziativer Caches versuchen abzumildern.
}

\section{Leistungssteigerung durch Cache}

\slides{03}{47}
\slides{03}{48}
\unimptnt{
\slides{03}{49}
}

\subsection{Gesamtgröße und Block(rahmen)größe}
\slides{03}{50}
\unimptnt{
\subsubsection{Einfluss der Blockrahmengröße}
\slides{03}{51}
}

\section{Nachladestrategien}
\subsection{Demand Fetching}
\slides{03}{52}
\subsection{Prefetching}
\subsubsection*{Was}
\slides{03}{53}
\subsubsection*{Wann}
\slides{03}{54}
\unimptnt{
\slides{03}{55}
}
Tagged Prefetch: Es wird nur weiter nachgeladen, wenn es sich zuvor „gelohnt“ hat ($\to$ ein Hit vorhanden war)

\section{Verdrängungsstrategien}
(Replacement Policy)
\slides{03}{56}
\subsection{Random, FIFO, Round Robin}
\slides{03}{57}
\subsection{LFU}
\slides{03}{58}
\subsection{LRU}
\slides{03}{59}
\unimptnt{
\subsubsection{Algorithmus}
\slides{03}{60}
}

\chapter{Speicher und Speicherverwaltung}
\section*{Hauptspeicher}
\slides{04}{1}
\section{Virtueller Speicher}
\subsection{Ziel}
\slides{04}{2}
\subsection{Virtueller Speicher}
\slides{04}{3}
\subsection{Speicherverwaltung: früher und heute}
\slides{04}{4}
\subsubsection{Begriffe}
\slides{04}{5}
\slides{04}{6}
\slides{04}{7}
\unimptnt{
\subsubsection{Anordnung von Cache und MMU}
\slides{04}{8}
}

\section{Dynamische Zuordnungsverfahren}
\subsection{Relocation}
\slides{04}{9}
\unimptnt{
\subsubsection*{Beispiel}
\slides{04}{10}
}
\subsubsection{Probleme}
\slides{04}{11}
\subsection{Paging}
\subsubsection{Methode}
\slides{04}{12}
\subsubsection{Prinzip der virtuellen Speicherverwaltung}
\slides{04}{13}
\subsubsection{Organisation der Seitentabellen}
\slides{04}{14}

\subsubsection{Einstufige Adressumsetzung}
\slides{04}{15}

\subsubsection*{Adressierung / Adressumsetzung}
\slides{04}{16}
\unimptnt{
\slides{04}{17}
\subsubsection*{Demand Paging}
„Seitennachladen nach Bedarf“: Nur die Seiten (Programmelemente) werden nachgeladen, die benötigt werden.
\subsubsection*{Demand Paging - Page Faults}
\slides{04}{18}
\subsubsection*{Beispiel}
\begin{itemize}
\item 32 Bit virtuelle Adresse ($\to$ 4 GiByte virtueller Adressraum)
\item 1 MiByte ($=2^{20}$ Byte) realer Speicher
\item Seitengröße 4 KiByte ($=2^{12}$ Byte), Adressauflösung: 1 Byte\\
$\Rightarrow$ virtueller Seitennummer 32-12 = 20 Bit\\
$\Rightarrow 2^{20}$ Einträge in der Page Table
\item 1 MiByte Hauptspeicher $\Rightarrow 2^{20-12}=2^8=256$ Seitenrahmen\\
$\Rightarrow$ PTE.Rp benötigt 8 Bit = 1 Byte, 1 weiteres Byte für P, RWX etc.\\
$\Rightarrow$ $2^{20}$ Einträge a 2 Byte $\Rightarrow$ 2 MiByte für Page Table!!! (Konflikt zu 1 MiByte realer Speicher)\\
$\Rightarrow$ PT ebenfalls im virtueller Adressraum, muss auch dem Demand Paging unterliegen…
\end{itemize}
$\Rightarrow$ Dieser Aufwand wird \emph{Table Superfluity} genannt.\bigskip\\
Anderes Szenario:
\begin{itemize}
\item 32 Bit virtuelle Adresse ($\to$ 4 GiByte virtueller Adressraum)
\item 256 MiByte ($=2^{28}$ Byte) realer Speicher
\item Seitengröße 4 KiByte ($=2^{12}$ Byte), Adressauflösung: 1 Byte\\
$\Rightarrow$ virtueller Seitennummer 32-12 = 20 Bit\\
$\Rightarrow 2^{20}$ Einträge in der Page Table
\item 1 MiByte Hauptspeicher $\Rightarrow 2^{28-12}=2^{16}=65.536$ Seitenrahmen\\
$\Rightarrow$ PTE.Rp benötigt 16 Bit = 2 Byte, 1 weiteres Byte für P, RWX etc.\\
$\Rightarrow$ $2^{20}$ Einträge a 3 Byte $\Rightarrow$ 3 MiByte für Page Table\\
$\Rightarrow$ PT kann im realen Hauptspeicher gehalten werden
\end{itemize}
$\Rightarrow$ Dieser Aufwand wird \emph{Table Superfluity} genannt.
}
\subsubsection{Zweistufige Adressumsetzung}
\slides{04}{19}

\subsubsection{Inverted Page Table}
\slides{04}{20}
\unimptnt{
\slides{04}{21}
\subsubsection*{Adressumsetzung}
\slides{04}{22}
\slides{04}{23}
}
\subsection{Segmentation}
\subsubsection{Methode}
\slides{04}{24}
\unimptnt{
\subsubsection{Adressierung / Adressumsetzung}
\slides{04}{25}
}
\subsubsection{Externe Fragmentierung}
\slides{04}{26}
\unimptnt{
\subsubsection{Kompaktierung}
\slides{04}{27}
}

\subsection{Paged Segmentation}
\slides{04}{28}
\unimptnt{
\slides{04}{29}
}

\section{Speicherverwaltungsverfahren}
\subsection{Überblick}
\slides{04}{30}
\subsection{Fetch / Placement}
\slides{04}{31}

\section{Translation Lookaside Buffer}
\slides{04}{32}

\unimptnt{
\subsection{Adressumsetzung}
\slides{04}{33}
}

\subsection{Ansatz}
\slides{04}{34}

\subsection{Probleme}
\slides{04}{35}
\unimptnt{
\slides{04}{36}
}
$\Rightarrow$ In modernen Systemen mit stets wechselnden Prozessen lohnt sich kein zu großer TLB, da er mit jedem Prozess neu beschrieben wird. Wird also der Prozess gewechselt, was regelmäßig geschieht, ist der gesamte TLB ungültig… obwohl der vorhergehende Prozess ihn wahrscheinlich gar nicht komplett füllen konnte.