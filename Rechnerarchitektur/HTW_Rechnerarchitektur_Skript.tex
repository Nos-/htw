\newcommand{\customDir}{../}
\input{\customDir .LaTeX_master/LaTeX_master_setup.sty}

%\setboolean{twosided}{true}
%\setCustomDocumentClass{scrartcl}
%\setCustomDesign{htw}
\setCustomSlidePath{Vorlesung/RA_043_}
\setCustomSlideScale{0.7}

\setCustomTitle{Rechnerarchitektur}
\setCustomSubtitle{Vorlesungsskript}
\setCustomAuthor{Falk-Jonatan Strube}
\setCustomNoteA{oder: „…aber das ist eine andere Geschichte“\vspace*{2em}}
\setCustomNoteB{Vorlesung von Prof. Dr.-Ing. Schönthier}

%\setcustomSignature{\footnotesize{\textcolor{darkgray}{Mitschrift von\\ \customAuthor}}	% Formatierung der Signatur in der Fußzeile
%\setcustomTitleAuthor{\textcolor{darkgray}{Mitschrift von #1}}	% Formatierung des Autors auf dem Titelblatt

\input{\customDir .LaTeX_master/LaTeX_master.sty}
\input{\customDir .LaTeX_master/LaTeX_master_macros.sty}

%\bibliography{\customDir .Literatur/HTW_Literatur.bib}

\makeatletter
\@addtoreset{chapter}{part}
\makeatother  

\begin{document}

%\selectlanguage{english}
\maketitle
\newpage
\tableofcontents
\newpage

%\chapter*{Vorbemerkung}
%Passwort Folien: \\% mi043##

% Folien i: eher weniger relevante Prüfungsinformationen
\part{Vorlesung}

\chapter{Architektur nach von Neumann}
\unimptnt{
%\slidesScale{01}{2}
\section*{Streiflicht: Konrad Zuse}
\slidesScale{01}{3}
\slidesScale{01}{4}
\section*{Streiflicht: John von Neumann}
\slidesScale{01}{5}

\section{Grundidee von von Neumann}
\slidesScale{01}{6}
}
\section{Grundarchitekturen von Rechnern/Computern}
\slidesScale{01}{7}
Havard-Architektur: Hardware-Aufwand größer durch mehr Busse

\section{Von-Neumann-Architektur}
\slidesScale{01}{8}
Im Speicher sind auf den ersten Blick von außen Daten und Befehle nicht voneinander zu unterschieden.
\slidesScale{01}{9}

\subsection{Kurzfassung Von-Neumann-Rechner Prinzip}
\slidesScale{01}{10}
\paragraph{Blockschaltbild}
\slidesScale{01}{11}
% Folie 12: Bild Wikipedia

\section{Befehlssequenz}
\slidesScale{01}{13}
Für Sprungbefehle werden für performante Ausführung Sprungvorhersagen benötigt.

\section{Operandenadressierung}
\slidesScale{01}{14}

\section{Architekturverfeinerung 1: Befehlszähler}
\slidesScale{01}{15}
\unimptnt{
$\Rightarrow$ Von-Neumann Rechner mit Befehlszähler
\slidesScale{01}{16}
}

\section{Klassischer Universalspeicher}
\subsection{Speicherwerk}
\slidesScale{01}{17}
\subsection{Rechenwerk}
\slidesScale{01}{18}
\unimptnt{
\subsubsection{Blockschaltbild einer ALU}
\slidesScale{01}{19}
}
\subsubsection{Flags/Bits des Statusregisters}
\slidesScale{01}{20}
$\mu P$: Mikroprozessor
\unimptnt{
\subsubsection*{Bsp.: Erzeugung des Bedingungsbits}
\slidesScale{01}{21}
}
\subsection{Steuerwerk}
\slidesScale{01}{22}
\subsection{CPU}
\slidesScale{01}{23}
\subsection{E/A-Werk und Bus}
\slidesScale{01}{24}

\section{Architekturverfeinerung 2: Einführung von Registern}
\slidesScale{01}{25}
\unimptnt{
\subsection{Von-Neumann-Rechner mit Register-Files}
\slidesScale{01}{26}
}

\section{Architekturverfeinerung 3: Erweiterung um relative Adressierung}
\slidesScale{01}{27}

\section{Universalrechner: Instruktionstypen / Befehlssatz}
\slidesScale{01}{29}

\paragraph{Beispielrechner: einfacher Von-Neumann-Beispielrechner}
\slidesScale{01}{28}

\subsection{Instruktionssatz}
\slidesScale{01}{30}

\subsection{Befehlszyklus}
\slidesScale{01}{31}

\unimptnt{
\subsubsection*{Bsp.: Interpretationszyklus des Beispielrechners}
\slidesScale{01}{32}
}

\section{Abweichungen moderner Rechner von den Von-Neumann-Prinzipien}
\slidesScale{01}{33}

\chapter{Prozessor}
\section*{Grundelemente des Prozessors} WICHTIG!
\slidesScale{02}{1}
\section{Rechenwerk}
\subsection*{Aufbau und Ansteuerung}
\slidesScale{02}{2}
\subsection*{Operationen einer (Ganzzahl-)ALU}
\slidesScale{02}{3}

\subsection{Addierer}
\subsubsection*{Addierwerk}
\slidesScale{02}{4}
\subsubsection*{Parallele Addierer: Ripple Carry Addierer (RCA)}
\slidesScale{02}{5}
\subsubsection*{Parallele Addierer: Carry-Look-Ahead-Addierer (CLA)}
\slidesScale{02}{6}

\subsection{Multiplizierer}
\unimptnt{
\subsubsection{Multiplikation von Dualzahlen}
\slidesScale{02}{7}
}

\subsubsection{Multiplizierwerk::seriell}
\slidesScale{02}{8}
\subsubsection{Multiplizierwerk::parallel}
\slidesScale{02}{9}

\unimptnt{
\subsubsection{Weitere Multiplizierwerke}
\begin{itemize}
\item Wallace Tree
\item Binary Tree
\item Booth-Algorithmus
\item Carry Save Multiplier
\end{itemize}
}

\section{Steuerwerk}

\subsection*{Grundaufgaben}
\slidesScale{02}{10}
\subsection*{Phaseneinteilung der Befehlsbearbeitung}
\slidesScale{02}{11}
\subsection*{Steuerwerk und Operationswerk}
\slidesScale{02}{12}
\subsection*{Realisierungstechniken}
\slidesScale{02}{13}

\unimptnt{
\subsection{Steuerwerk als Automat}
\subsubsection*{Finite State Machine (FSM) = endlicher Automat}
\slidesScale{02}{14}
\subsubsection*{Logikrealisierung}
\slidesScale{02}{15}
\slidesScale{02}{16}

\subsection*{Beispiele}
\begin{itemize}
\item „sequentieller Addierer“ Datenpfad\\
Zustände laut Algorithmus:
\begin{enumerate}
\item „Laden von Summand A“
\item „Laden von Summand B“
\item „Übernahme des Additionsergebnisses“
\item „Weiterschalten der Summanden um eine Stelle“
\item „Ausgabe des Ergebnisses“
\end{enumerate}
\end{itemize}
}

\subsection{Steuerwerk mit Mikroprogrammierung}

\subsubsection{Realisierung}
\slidesScale{02}{17}
\unimptnt{
\subsubsection*{Aufbau eines einfachen Mikroprogramm-Steuerwerk}
\slidesScale{02}{18}
}
\subsubsection{Mikroprogrammierung: Vor- und Nachteile}
\slidesScale{02}{19}
\subsubsection{Unterschied mikroprogrammiert/mikroprogrammierbar}
\slidesScale{02}{20}

\section{Adresswerk}
(Address Unit, Address Generation Logic)
\slidesScale{02}{21}

\unimptnt{
\subsection*{Aufbau eines einfachen Adresswerks}
\slidesScale{02}{22}
\slidesScale{02}{23}
}

\chapter{Speicherhierarchie und Cache}
%\subsection*{Speicherverwaltung: Einführung}
\slidesScale{03}{2}
\section{Speicherhierarchie}
\slidesScale{03}{3}

\subsection{Ebenen}
\slidesScale{03}{4}
\slidesScale{03}{5}

\section{Cache}
\subsection{Einführung}
\subsubsection{Motivation und Grundidee}
\slidesScale{03}{6}

\subsubsection{Umsetzung der Idee}
\slidesScale{03}{7}
\slidesScale{03}{8}

\subsubsection{Hierarchie, Übertragungsmodi}
\slidesScale{03}{9}

\subsection{Lokalität}
\subsubsection{Prinzip}
\slidesScale{03}{10}
Beispiel Lokalität: Wenn man bei C Arrays multipliziert, kann je nach Schachtelung der Schleifen die Laufzeit leiden. In C werden Arrays zeilenweise gespeichert, multipliziert man die Arrays allerdings spaltenweise, so muss viel gesprungen werden, da die Speicherblöcke weiter auseinander liegen.

\subsubsection{Zeitliche Lokalität}
(Temporal Locality)
\slidesScale{03}{11}

\subsubsection{Räumliche Lokalität}
(Spatial Locality)
\slidesScale{03}{12}

\subsubsection{Bedeutung der Lokalität}
\slidesScale{03}{13}

\subsubsection{Umsetzung des Lokalitätsprinzips}
\slidesScale{03}{14}

\subsection{Zugriff}
\subsubsection{Anordnung bezüglich CPU und Hauptspeicher}
\slidesScale{03}{15}
\subsubsection{Fehlzugriffe}
\slidesScale{03}{16}
weiterhin:
\slidesScale{03}{17}
\subsubsection*{Compulsory-Miss}
\slidesScale{03}{18}

\subsubsection{Lesezugriffe}
\slidesScale{03}{19}

\subsubsection{Schreibzugriffe}
\subsubsection*{Rückschreibestrategien}
\slidesScale{03}{20}
\subsubsection*{Durchschreibverfahren}
\slidesScale{03}{21}
\subsubsection*{Rückschreibeverfahren}
\slidesScale{03}{22}
\subsubsection*{Write Hit und Write Miss}
\slidesScale{03}{23}

\subsection{Kohärenz und Konsistenz}
\subsubsection{Kohärenz}
„Alle Speicherzugreifenden bekommen den richtigen Wert, wenn sie auf den Speicher zugreifen“
\unimptnt{
\subsubsection*{Kohärenz Beispiel mit Write-Through-Caches}
\slidesScale{03}{24}
\subsubsection*{Kohärenz Beispiel mit Write-Back-Caches}
\slidesScale{03}{25}
}

\subsubsection*{Speicherkohärenz}
\slidesScale{03}{26}

\subsubsection*{Definition Kohärenz}
\slidesScale{03}{27}
\slidesScale{03}{28}

\subsubsection{Konsistenz}
\slidesScale{03}{29}

\unimptnt{
\subsubsection*{Speicher-Konsistenz}
\slidesScale{03}{30}
}

\subsubsection{Kohärenz-Protokolle}
\slidesScale{03}{31}
\unimptnt{
\subsubsection*{Vereichnisbasiert}
\slidesScale{03}{32}

\subsubsection*{Bus-Snooping}
\slidesScale{03}{33}

Möglichkeiten:
\slidesScale{03}{34}

\subsubsection*{MESI-Kohärenzprotokoll}
\slidesScale{03}{35}
Verbesserungen:
\slidesScale{03}{36}

\subsubsection*{Update-basierte Protokolle}
\slidesScale{03}{37}
}

\section{Cacheorganisation}

\subsection{Realisierung}
\slidesScale{03}{38}

\subsection{Aufbau eines Cache-Speichers}
\slidesScale{03}{39}

\subsection{Begriffe}
\slidesScale{03}{40}

\subsection{Direktabbildender Cache}
(Direct Mapped Cache)
\slidesScale{03}{41}
Beispiel: Direkt abgebildeter Cache mit 8 Einträgen, Speicher mit $2^5$ Adressen: Die letzten Bits der Speicheradressen bestimmen die Position im Cache: $00001$, $01001$, $10001$ und $11001$ landen im Cache-Block $001$.
\unimptnt{
\slidesScale{03}{42}
}

\subsection{vollassoziativer Cache}
(Fully Associative Cache)
\slidesScale{03}{43}

\subsection{p-fach satzassoziativer Cache}
\slidesScale{03}{44}
\unimptnt{
\slidesScale{03}{45}

\subsection{Cache-Mapping: zusammenfassendes Beispiel}
\slidesScale{03}{46}
Die 2. und 3. Caches geben dem Cache also eine Struktur vor, die die Nachteile des voll-assoziativer Caches versuchen abzumildern.
}

\section{Leistungssteigerung durch Cache}

\slidesScale{03}{47}
\slidesScale{03}{48}
\unimptnt{
\slidesScale{03}{49}
}

\subsection{Gesamtgröße und Block(rahmen)größe}
\slidesScale{03}{50}
\unimptnt{
\subsubsection{Einfluss der Blockrahmengröße}
\slidesScale{03}{51}
}

\section{Nachladestrategien}
\subsection{Demand Fetching}
\slidesScale{03}{52}
\subsection{Prefetching}
\subsubsection*{Was}
\slidesScale{03}{53}
\subsubsection*{Wann}
\slidesScale{03}{54}
\unimptnt{
\slidesScale{03}{55}
}
Tagged Prefetch: Es wird nur weiter nachgeladen, wenn es sich zuvor „gelohnt“ hat ($\to$ ein Hit vorhanden war)

\section{Verdrängungsstrategien}
(Replacement Policy)
\slidesScale{03}{56}
\subsection{Random, FIFO, Round Robin}
\slidesScale{03}{57}
\subsection{LFU}
\slidesScale{03}{58}
\subsection{LRU}
\slidesScale{03}{59}
\unimptnt{
\subsubsection{Algorithmus}
\slidesScale{03}{60}
}

\chapter{Speicher und Speicherverwaltung}
\section*{Hauptspeicher}
\slidesScale{04}{1}
\section{Virtueller Speicher}
\subsection{Ziel}
\slidesScale{04}{2}
\subsection{Virtueller Speicher}
\slidesScale{04}{3}
\subsection{Speicherverwaltung: früher und heute}
\slidesScale{04}{4}
\subsubsection{Begriffe}
\slidesScale{04}{5}
\slidesScale{04}{6}
\slidesScale{04}{7}
\unimptnt{
\subsubsection{Anordnung von Cache und MMU}
\slidesScale{04}{8}
}

\section{Dynamische Zuordnungsverfahren}
\subsection{Relocation}
\slidesScale{04}{9}
\unimptnt{
\subsubsection*{Beispiel}
\slidesScale{04}{10}
}
\subsubsection{Probleme}
\slidesScale{04}{11}
\subsection{Paging}
\subsubsection{Methode}
\slidesScale{04}{12}
\subsubsection{Prinzip der virtuellen Speicherverwaltung}
\slidesScale{04}{13}
\subsubsection{Organisation der Seitentabellen}
\slidesScale{04}{14}

\subsubsection{Einstufige Adressumsetzung}
\slidesScale{04}{15}

\subsubsection*{Adressierung / Adressumsetzung}
\slidesScale{04}{16}
\unimptnt{
\slidesScale{04}{17}
\subsubsection*{Demand Paging}
„Seitennachladen nach Bedarf“: Nur die Seiten (Programmelemente) werden nachgeladen, die benötigt werden.
\subsubsection*{Demand Paging - Page Faults}
\slidesScale{04}{18}
\subsubsection*{Beispiel}
\begin{itemize}
\item 32 Bit virtuelle Adresse ($\to$ 4 GiByte virtueller Adressraum)
\item 1 MiByte ($=2^{20}$ Byte) realer Speicher
\item Seitengröße 4 KiByte ($=2^{12}$ Byte), Adressauflösung: 1 Byte\\
$\Rightarrow$ virtueller Seitennummer 32-12 = 20 Bit\\
$\Rightarrow 2^{20}$ Einträge in der Page Table
\item 1 MiByte Hauptspeicher $\Rightarrow 2^{20-12}=2^8=256$ Seitenrahmen\\
$\Rightarrow$ PTE.Rp benötigt 8 Bit = 1 Byte, 1 weiteres Byte für P, RWX etc.\\
$\Rightarrow$ $2^{20}$ Einträge a 2 Byte $\Rightarrow$ 2 MiByte für Page Table!!! (Konflikt zu 1 MiByte realer Speicher)\\
$\Rightarrow$ PT ebenfalls im virtueller Adressraum, muss auch dem Demand Paging unterliegen…
\end{itemize}
$\Rightarrow$ Dieser Aufwand wird \emph{Table Superfluity} genannt.\bigskip\\
Anderes Szenario:
\begin{itemize}
\item 32 Bit virtuelle Adresse ($\to$ 4 GiByte virtueller Adressraum)
\item 256 MiByte ($=2^{28}$ Byte) realer Speicher
\item Seitengröße 4 KiByte ($=2^{12}$ Byte), Adressauflösung: 1 Byte\\
$\Rightarrow$ virtueller Seitennummer 32-12 = 20 Bit\\
$\Rightarrow 2^{20}$ Einträge in der Page Table
\item 1 MiByte Hauptspeicher $\Rightarrow 2^{28-12}=2^{16}=65.536$ Seitenrahmen\\
$\Rightarrow$ PTE.Rp benötigt 16 Bit = 2 Byte, 1 weiteres Byte für P, RWX etc.\\
$\Rightarrow$ $2^{20}$ Einträge a 3 Byte $\Rightarrow$ 3 MiByte für Page Table\\
$\Rightarrow$ PT kann im realen Hauptspeicher gehalten werden
\end{itemize}
$\Rightarrow$ Dieser Aufwand wird \emph{Table Superfluity} genannt.
}
\subsubsection{Zweistufige Adressumsetzung}
\slidesScale{04}{19}

\chapter{Pipelining}

\chapter{Sprungvorhersage}

\chapter{Superskalare Architekturen, Parallelisierung}

\chapter{Leistungsbewertung}

\chapter{Informationstransport: Bus, Protokolle}

\chapter{E/A und Interrupts}

%\input{HTW_Rechnerarchitektur_Skript_Praktikum}

%\newpage
%\printbibliography

\end{document}
